{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ba38cb80-e5aa-4772-b9ca-472481bf99c5",
   "metadata": {},
   "source": [
    "# Fake News detection"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "980c764d-58fd-48c9-af6c-688f8a25e9c6",
   "metadata": {},
   "source": [
    "## Load Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "16085483-adb9-4ea3-8680-bcdec888ac5e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                               title  \\\n",
      "0  Ben Stein Calls Out 9th Circuit Court: Committ...   \n",
      "1  Trump drops Steve Bannon from National Securit...   \n",
      "2  Puerto Rico expects U.S. to lift Jones Act shi...   \n",
      "3   OOPS: Trump Just Accidentally Confirmed He Le...   \n",
      "4  Donald Trump heads for Scotland to reopen a go...   \n",
      "\n",
      "                                                text       subject  \\\n",
      "0  21st Century Wire says Ben Stein, reputable pr...       US_News   \n",
      "1  WASHINGTON (Reuters) - U.S. President Donald T...  politicsNews   \n",
      "2  (Reuters) - Puerto Rico Governor Ricardo Rosse...  politicsNews   \n",
      "3  On Monday, Donald Trump once again embarrassed...          News   \n",
      "4  GLASGOW, Scotland (Reuters) - Most U.S. presid...  politicsNews   \n",
      "\n",
      "                  date  label  \n",
      "0    February 13, 2017      1  \n",
      "1       April 5, 2017       0  \n",
      "2  September 27, 2017       0  \n",
      "3         May 22, 2017      1  \n",
      "4       June 24, 2016       0  \n",
      "label\n",
      "1    23481\n",
      "0    21417\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "fake_df = pd.read_csv(\"Fake.csv\")\n",
    "true_df = pd.read_csv(\"True.csv\")\n",
    "\n",
    "fake_df[\"label\"] = 1\n",
    "true_df[\"label\"] = 0\n",
    "\n",
    "df = pd.concat([fake_df, true_df], axis=0).reset_index(drop=True)\n",
    "\n",
    "df = df.sample(frac=1, random_state=42).reset_index(drop=True)\n",
    "\n",
    "print(df.head())\n",
    "print(df[\"label\"].value_counts())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc43a5e7-4c6e-42dd-977e-22aae4cea2e6",
   "metadata": {},
   "source": [
    "## Clean the Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0ecfa61f-1cbc-4c94-b915-7b1c8c71f19e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: nltk in c:\\users\\mbuzii\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (3.9.2)\n",
      "Requirement already satisfied: click in c:\\users\\mbuzii\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from nltk) (8.3.0)\n",
      "Requirement already satisfied: joblib in c:\\users\\mbuzii\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from nltk) (1.5.1)\n",
      "Requirement already satisfied: regex>=2021.8.3 in c:\\users\\mbuzii\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from nltk) (2025.9.1)\n",
      "Requirement already satisfied: tqdm in c:\\users\\mbuzii\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from nltk) (4.67.1)\n",
      "Requirement already satisfied: colorama in c:\\users\\mbuzii\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from click->nltk) (0.4.6)\n"
     ]
    }
   ],
   "source": [
    "!pip install nltk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "14807fb8-c744-4afe-a62c-e45da0b8dcb2",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\mbuzii\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                text  \\\n",
      "0  21st Century Wire says Ben Stein, reputable pr...   \n",
      "1  WASHINGTON (Reuters) - U.S. President Donald T...   \n",
      "2  (Reuters) - Puerto Rico Governor Ricardo Rosse...   \n",
      "3  On Monday, Donald Trump once again embarrassed...   \n",
      "4  GLASGOW, Scotland (Reuters) - Most U.S. presid...   \n",
      "\n",
      "                                           CleanText  \n",
      "0  21st century wire says ben stein reputable pro...  \n",
      "1  washington reuters u president donald trump re...  \n",
      "2  reuters puerto rico governor ricardo rossello ...  \n",
      "3  monday donald trump embarrassed country accide...  \n",
      "4  glasgow scotland reuters u presidential candid...  \n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "\n",
    "nltk.download('stopwords')\n",
    "stop_words = set(stopwords.words('english'))\n",
    "\n",
    "def clean_text(text):\n",
    "    text = re.sub(r'\\W', ' ', str(text))      \n",
    "    text = re.sub(r'\\s+', ' ', text)          \n",
    "    text = text.lower()                       \n",
    "    text = ' '.join(word for word in text.split() if word not in stop_words)  \n",
    "    return text\n",
    "\n",
    "df['CleanText'] = df['text'].apply(clean_text)\n",
    "\n",
    "print(df[['text', 'CleanText']].head())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b5a9779-0445-47c4-bde1-67a623f9a230",
   "metadata": {},
   "source": [
    "## Split the Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3398c470-5537-4f0a-9efd-650b3a9ce9c8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training samples: 35918\n",
      "Testing samples: 8980\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X = df['CleanText'].values\n",
    "y = df['label'].values\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.2, random_state=42\n",
    ")\n",
    "\n",
    "print(\"Training samples:\", len(X_train))\n",
    "print(\"Testing samples:\", len(X_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97209c07-3988-4e63-9a20-794679b326e6",
   "metadata": {},
   "source": [
    "## Tokenization and Padding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "88eab0ee-bfdf-434c-9886-b5a7c6efa0ce",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train_pad shape: (35918, 100)\n",
      "X_test_pad shape: (8980, 100)\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "\n",
    "max_words = 10000\n",
    "max_len = 100\n",
    "\n",
    "tokenizer = Tokenizer(num_words=max_words)\n",
    "tokenizer.fit_on_texts(X_train)\n",
    "\n",
    "X_train_seq = tokenizer.texts_to_sequences(X_train)\n",
    "X_test_seq = tokenizer.texts_to_sequences(X_test)\n",
    "\n",
    "X_train_pad = pad_sequences(X_train_seq, maxlen=max_len)\n",
    "X_test_pad = pad_sequences(X_test_seq, maxlen=max_len)\n",
    "\n",
    "print(\"X_train_pad shape:\", X_train_pad.shape)\n",
    "print(\"X_test_pad shape:\", X_test_pad.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27a78584-8307-4467-9c1c-ddb904ddc42e",
   "metadata": {},
   "source": [
    "## Build the LSTM Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c3b85d79-d6c1-4758-a568-79a277d72c53",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\mbuzii\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\keras\\src\\layers\\core\\embedding.py:97: UserWarning: Argument `input_length` is deprecated. Just remove it.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"sequential\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                         </span>┃<span style=\"font-weight: bold\"> Output Shape                </span>┃<span style=\"font-weight: bold\">         Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n",
       "│ embedding (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Embedding</span>)                │ ?                           │     <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (unbuilt) │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ lstm (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LSTM</span>)                          │ ?                           │     <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (unbuilt) │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dense (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                        │ ?                           │     <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (unbuilt) │\n",
       "└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                        \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape               \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m        Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n",
       "│ embedding (\u001b[38;5;33mEmbedding\u001b[0m)                │ ?                           │     \u001b[38;5;34m0\u001b[0m (unbuilt) │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ lstm (\u001b[38;5;33mLSTM\u001b[0m)                          │ ?                           │     \u001b[38;5;34m0\u001b[0m (unbuilt) │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dense (\u001b[38;5;33mDense\u001b[0m)                        │ ?                           │     \u001b[38;5;34m0\u001b[0m (unbuilt) │\n",
       "└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Embedding, LSTM, Dense, Dropout\n",
    "\n",
    "# Build the model\n",
    "model = Sequential()\n",
    "model.add(Embedding(input_dim=max_words, output_dim=128, input_length=max_len))\n",
    "model.add(LSTM(128, dropout=0.2, recurrent_dropout=0.2))\n",
    "model.add(Dense(1, activation='sigmoid'))  \n",
    "\n",
    "# Compile the model\n",
    "model.compile(\n",
    "    loss='binary_crossentropy',\n",
    "    optimizer='adam',\n",
    "    metrics=['accuracy']\n",
    ")\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f141dba-49d0-47ea-828b-829f51fbdc5b",
   "metadata": {},
   "source": [
    "## Train the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab422a56-0a54-45a6-9b09-cb7f3df0105c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3\n",
      "\u001b[1m 66/225\u001b[0m \u001b[32m━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━\u001b[0m \u001b[1m6:33\u001b[0m 2s/step - accuracy: 0.8085 - loss: 0.4583"
     ]
    }
   ],
   "source": [
    "history = model.fit(\n",
    "    X_train_pad, y_train,\n",
    "    epochs=3,          \n",
    "    batch_size=128,\n",
    "    validation_split=0.2, \n",
    "    verbose=1\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ebba4f1-d66c-4720-aa9b-6d889222fba4",
   "metadata": {},
   "source": [
    "## Evaluate the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d15213fc-7318-4f29-852c-52896f697155",
   "metadata": {},
   "outputs": [],
   "source": [
    "loss, accuracy = model.evaluate(X_test_pad, y_test, verbose=1)\n",
    "print(\"Test Accuracy:\", accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4a300e3-eb2e-4b6c-aea8-e03bdae63be4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "predictions = (model.predict(X_test_pad) > 0.5).astype(\"int32\")\n",
    "print(predictions[:10].flatten())  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35c4d879-ed15-4d46-929d-f3b5baabae3f",
   "metadata": {},
   "source": [
    "## analyze the model in more detail"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03693a5d-745e-4c66-9640-17a6aa7eae30",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "y_pred = (model.predict(X_test_pad) > 0.5).astype(\"int32\")\n",
    "\n",
    "cm = confusion_matrix(y_test, y_pred)\n",
    "sns.heatmap(cm, annot=True, fmt=\"d\", cmap=\"Blues\")\n",
    "plt.xlabel(\"Predicted\")\n",
    "plt.ylabel(\"Actual\")\n",
    "plt.show()\n",
    "\n",
    "print(classification_report(y_test, y_pred, target_names=[\"Real\", \"Fake\"]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "204470a4-3c86-469d-91ee-d95480325987",
   "metadata": {},
   "source": [
    "## visualize training progress"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68ddd030-af0c-4952-bc21-a5bec6554059",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.plot(history.history['accuracy'], label='Train Accuracy')\n",
    "plt.plot(history.history['val_accuracy'], label='Validation Accuracy')\n",
    "plt.title('Model Accuracy')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "plt.plot(history.history['loss'], label='Train Loss')\n",
    "plt.plot(history.history['val_loss'], label='Validation Loss')\n",
    "plt.title('Model Loss')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Loss')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e0317d7-e69b-4a44-8005-8f640b680552",
   "metadata": {},
   "source": [
    "## Predicting New News Articles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46797a5d-8d20-4900-9d51-3151d3ed22f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "new_articles = [\n",
    "    \"Breaking: Scientists discover a new cure for common cold.\",\n",
    "    \"Celebrity endorses miracle weight loss pill.\"\n",
    "]\n",
    "\n",
    "new_clean = [clean_text(text) for text in new_articles]\n",
    "\n",
    "new_seq = tokenizer.texts_to_sequences(new_clean)\n",
    "\n",
    "new_pad = pad_sequences(new_seq, maxlen=max_len)\n",
    "\n",
    "predictions = (model.predict(new_pad) > 0.5).astype(\"int32\")\n",
    "for text, pred in zip(new_articles, predictions):\n",
    "    label = \"Fake\" if pred[0] == 1 else \"Real\"\n",
    "    print(f\"Article: {text}\\nPrediction: {label}\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55a4084e-8f23-4379-9d9f-deabc7500a0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_articles = [\n",
    "    \"The government announced a new education policy starting next month.\",\n",
    "    \"Local team wins the national soccer championship.\",\n",
    "    \"Miracle cure for diabetes discovered in remote village.\",\n",
    "    \"Stock market sees steady growth after quarterly earnings report.\"\n",
    "]\n",
    "\n",
    "test_clean = [clean_text(text) for text in test_articles]\n",
    "\n",
    "test_seq = tokenizer.texts_to_sequences(test_clean)\n",
    "\n",
    "test_pad = pad_sequences(test_seq, maxlen=max_len)\n",
    "\n",
    "predictions = (model.predict(test_pad) > 0.5).astype(\"int32\")\n",
    "\n",
    "for text, pred in zip(test_articles, predictions):\n",
    "    label = \"Fake\" if pred[0] == 1 else \"Real\"\n",
    "    print(f\"Article: {text}\\nPrediction: {label}\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c049c7f5-abc3-4a4d-956c-ac360eba2a5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(df['label'].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9cf8933a-a5aa-4638-8b8b-575fd4c2553c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.utils import class_weight\n",
    "import numpy as np\n",
    "\n",
    "class_weights = class_weight.compute_class_weight(\n",
    "    class_weight='balanced',\n",
    "    classes=np.unique(y_train),\n",
    "    y=y_train\n",
    ")\n",
    "class_weights_dict = dict(enumerate(class_weights))\n",
    "print(class_weights_dict)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5584e9db-efbc-4bd6-a018-8800b145c998",
   "metadata": {},
   "source": [
    "## Retrain Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7bd73dbc-cefa-446b-8f66-33f84492ec2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "history = model.fit(\n",
    "    X_train_pad, y_train,\n",
    "    epochs=5,                \n",
    "    batch_size=128,\n",
    "    validation_split=0.2,\n",
    "    class_weight={0:1.047, 1:0.957},\n",
    "    verbose=1\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7cfc0f7e-4dbf-4e86-bf51-9ea97440571b",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_articles = [\n",
    "    \"The government announced a new education policy starting next month.\",\n",
    "    \"Local team wins the national soccer championship.\",\n",
    "    \"Miracle cure for diabetes discovered in remote village.\",\n",
    "    \"Stock market sees steady growth after quarterly earnings report.\"\n",
    "]\n",
    "\n",
    "test_clean = [clean_text(text) for text in test_articles]\n",
    "test_seq = tokenizer.texts_to_sequences(test_clean)\n",
    "test_pad = pad_sequences(test_seq, maxlen=max_len)\n",
    "\n",
    "predictions = (model.predict(test_pad) > 0.5).astype(\"int32\")\n",
    "\n",
    "for text, pred in zip(test_articles, predictions):\n",
    "    label = \"Fake\" if pred[0] == 1 else \"Real\"\n",
    "    print(f\"Article: {text}\\nPrediction: {label}\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb3163fe-5ad0-4fd4-ab4b-c6d65c24384d",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['label'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d3238fe-36fe-45c0-84f8-d2d37090449c",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['full_text'] = df['title'] + \" \" + df['text']\n",
    "X = df['full_text'].values\n",
    "y = df['label'].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e614d879-c108-4f84-bd20-19a5a9d12de9",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['full_text'] = df['title'] + \" \" + df['text']\n",
    "\n",
    "df['CleanText'] = df['full_text'].apply(clean_text)\n",
    "\n",
    "print(df[['full_text', 'CleanText']].head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e80de92-6ec1-4cd4-b264-37a0eb961dae",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X = df['CleanText'].values\n",
    "y = df['label'].values\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.2, random_state=42\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d59d5355-9f1e-425e-8522-f2c43deaee3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "\n",
    "max_words = 10000\n",
    "max_len = 200  \n",
    "\n",
    "tokenizer = Tokenizer(num_words=max_words)\n",
    "tokenizer.fit_on_texts(X_train)\n",
    "\n",
    "X_train_seq = tokenizer.texts_to_sequences(X_train)\n",
    "X_test_seq = tokenizer.texts_to_sequences(X_test)\n",
    "\n",
    "X_train_pad = pad_sequences(X_train_seq, maxlen=max_len)\n",
    "X_test_pad = pad_sequences(X_test_seq, maxlen=max_len)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c55c004c-2698-4df8-8665-90bd53bc4751",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Embedding, LSTM, Dense, Dropout\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Embedding(input_dim=max_words, output_dim=128, input_length=max_len))\n",
    "model.add(LSTM(128, dropout=0.2, recurrent_dropout=0.2))\n",
    "model.add(Dense(1, activation='sigmoid'))\n",
    "\n",
    "model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c9010e4-cf4a-4957-9c11-46469bf0b516",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.utils import class_weight\n",
    "import numpy as np\n",
    "\n",
    "class_weights = class_weight.compute_class_weight(\n",
    "    class_weight='balanced',\n",
    "    classes=np.unique(y_train),\n",
    "    y=y_train\n",
    ")\n",
    "class_weights_dict = dict(enumerate(class_weights))\n",
    "print(class_weights_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e24b5aa8-6d17-42c1-97fe-7f2c916dbd50",
   "metadata": {},
   "outputs": [],
   "source": [
    "history = model.fit(\n",
    "    X_train_pad, y_train,\n",
    "    epochs=5,\n",
    "    batch_size=128,\n",
    "    validation_split=0.2,\n",
    "    class_weight=class_weights_dict,\n",
    "    verbose=1\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9c15027-b460-420b-b255-3b00c4ec250d",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_loss, test_accuracy = model.evaluate(X_test_pad, y_test)\n",
    "print(f\"Test Accuracy: {test_accuracy}\")\n",
    "print(f\"Test Loss: {test_loss}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2bf0a5b3-9f38-40fb-87cc-e2e77f3f8d6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "new_articles = [\n",
    "    \"The government announced a new education policy starting next month.\",\n",
    "    \"Local team wins the national soccer championship.\",\n",
    "    \"Miracle cure for diabetes discovered in remote village.\",\n",
    "    \"Stock market sees steady growth after quarterly earnings report.\"\n",
    "]\n",
    "\n",
    "new_clean = [clean_text(text) for text in new_articles]\n",
    "new_seq = tokenizer.texts_to_sequences(new_clean)\n",
    "new_pad = pad_sequences(new_seq, maxlen=max_len)\n",
    "\n",
    "predictions = (model.predict(new_pad) > 0.5).astype(\"int32\")\n",
    "\n",
    "for text, pred in zip(new_articles, predictions):\n",
    "    label = \"Fake\" if pred[0] == 1 else \"Real\"\n",
    "    print(f\"Article: {text}\\nPrediction: {label}\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cabbe75c-581c-40ec-9eb9-87f9788e6cd8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "\n",
    "y_pred = (model.predict(X_test_pad) > 0.5).astype(\"int32\")\n",
    "\n",
    "print(confusion_matrix(y_test, y_pred))\n",
    "print(classification_report(y_test, y_pred, digits=4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e791b46a-411a-45c0-857d-31eb3fd2fe85",
   "metadata": {},
   "outputs": [],
   "source": [
    "texts = [\n",
    "    \"The government announced a new education policy starting next month.\",\n",
    "    \"Local team wins the national soccer championship.\",\n",
    "    \"Miracle cure for diabetes discovered in remote village.\",\n",
    "    \"Stock market sees steady growth after quarterly earnings report.\"\n",
    "]\n",
    "\n",
    "seqs = tokenizer.texts_to_sequences(texts)\n",
    "pad = pad_sequences(seqs, maxlen=max_len)\n",
    "probs = model.predict(pad)\n",
    "\n",
    "for i, p in enumerate(probs):\n",
    "    print(f\"Article: {texts[i]}\")\n",
    "    print(f\"Predicted Probability: {p[0]:.4f}\")\n",
    "    print(\"Prediction:\", \"Real\" if p[0] > 0.5 else \"Fake\", \"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49da9287-3e4e-4521-ae4a-1cfeaaa1da9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save(\"fake_news_model.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7010ed25-2a68-440e-a7e5-dff982190845",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "with open(\"tokenizer.pkl\", \"wb\") as f:\n",
    "    pickle.dump(tokenizer, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5dcf7b4-a6e7-4989-97ed-cec52f1cdebb",
   "metadata": {},
   "outputs": [],
   "source": [
    "new_article = [\"Breaking: Scientists develop new vaccine for flu.\"]\n",
    "seq = tokenizer.texts_to_sequences(new_article)\n",
    "padded = pad_sequences(seq, maxlen=100)\n",
    "prob = model.predict(padded)[0][0]\n",
    "prediction = \"Real\" if prob > 0.5 else \"Fake\"\n",
    "print(f\"Prediction: {prediction}, Probability: {prob}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3e8661d-88a7-4546-8819-bf05e9b11292",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "import numpy as np\n",
    "from tensorflow.keras.models import load_model\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "\n",
    "model = load_model(\"fake_news_model.h5\")\n",
    "\n",
    "with open(\"tokenizer.pkl\", \"rb\") as f:\n",
    "    tokenizer = pickle.load(f)\n",
    "\n",
    "MAX_LEN = 100\n",
    "\n",
    "def predict_news(article):\n",
    "    seq = tokenizer.texts_to_sequences([article])\n",
    "    padded = pad_sequences(seq, maxlen=MAX_LEN)\n",
    "    prob = model.predict(padded)[0][0]\n",
    "    label = \"Real\" if prob > 0.5 else \"Fake\"\n",
    "    print(f\"Article: {article}\")\n",
    "    print(f\"Prediction: {label}, Probability: {prob:.4f}\\n\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    articles = [\n",
    "        \"The government announced a new education policy starting next month.\",\n",
    "        \"Local team wins the national soccer championship.\",\n",
    "        \"Miracle cure for diabetes discovered in remote village.\",\n",
    "        \"Stock market sees steady growth after quarterly earnings report.\"\n",
    "    ]\n",
    "    for article in articles:\n",
    "        predict_news(article)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5dea61e9-bacd-43f1-9a64-a49392ce80b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "from tensorflow.keras.models import load_model\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "\n",
    "model = load_model(\"fake_news_model.h5\")\n",
    "\n",
    "with open(\"tokenizer.pkl\", \"rb\") as f:\n",
    "    tokenizer = pickle.load(f)\n",
    "\n",
    "MAX_LEN = 100\n",
    "\n",
    "import re\n",
    "def clean_text(text):\n",
    "    text = text.lower()\n",
    "    text = re.sub(r'[^a-zA-Z0-9\\s]', '', text)\n",
    "    return text\n",
    "\n",
    "def predict_news(article):\n",
    "    article_clean = clean_text(article)\n",
    "    seq = tokenizer.texts_to_sequences([article_clean])\n",
    "    padded = pad_sequences(seq, maxlen=MAX_LEN)\n",
    "    prob = model.predict(padded)[0][0]\n",
    "    label = \"Real\" if prob > 0.5 else \"Fake\"\n",
    "    print(f\"\\nArticle: {article}\")\n",
    "    print(f\"Prediction: {label}, Probability: {prob:.4f}\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    while True:\n",
    "        user_input = input(\"\\nEnter a news article (or type 'exit' to quit):\\n\")\n",
    "        if user_input.lower() == \"exit\":\n",
    "            print(\"Exiting program.\")\n",
    "            break\n",
    "        predict_news(user_input)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "823a4f84-d3ea-4c32-a1e2-c13d806ec5c7",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.13",
   "language": "python",
   "name": "python313"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
